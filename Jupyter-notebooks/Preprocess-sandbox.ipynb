{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc12a2f4-ee76-4102-b0ef-289d42abb5da",
   "metadata": {},
   "source": [
    "## Define Variables / Import MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c8c05-354f-4662-8da3-5d17874a8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from cartopy import crs as ccrs \n",
    "import datetime\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e20ae-ce58-4b1b-a519-e878327e099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define misc variables\n",
    "amer_filepath = '../ameriflux-data/'\n",
    "mic_filepath = '../../micasa-data/'\n",
    "timedelta = 'DD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1456bfe7-896a-4f82-861b-8cfc04d5488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import site metadata csv\n",
    "meta_file = amer_filepath + 'AmeriFlux-site-search-results-202410071335.tsv'\n",
    "ameriflux_meta = pd.read_csv(meta_file, sep='\\t')\n",
    "fluxnet_meta = ameriflux_meta.loc[ameriflux_meta['AmeriFlux FLUXNET Data'] == 'Yes'] #use FLUXNET only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f99e08c-4328-46dd-a44c-05564dcff537",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sites = fluxnet_meta['Site ID'].to_list()\n",
    "len(total_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8592b63-873b-4f4f-8b20-30378804cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set map proj\n",
    "proj=ccrs.PlateCarree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822f6e09-5263-4085-b1ec-eacc96c7b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_match(pattern):\n",
    "    matches = glob.glob(pattern)\n",
    "    if len(matches) == 1:\n",
    "        return matches[0]\n",
    "    elif len(matches) == 0:\n",
    "        raise ValueError(f\"No matches found\")\n",
    "    else:\n",
    "        raise ValueError(f\"Multiple matches found: {matches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886f032-cfdb-442a-8918-830cfa71c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amer_match(amer_filepath, site_ID):\n",
    "    match = get_single_match(amer_filepath + 'AMF_' + site_ID +\n",
    "                            '_FLUXNET_SUBSET_*/AMF_' + site_ID +\n",
    "                            '_FLUXNET_SUBSET_' + timedelta + '*.csv')\n",
    "    return match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b982fa3-5935-496b-abd2-7f3b906b1d56",
   "metadata": {},
   "source": [
    "## B. Develop script to dump all variables requested into one preprocessed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31938bad-11eb-4cd0-b364-a37b69990605",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_ID = 'AR-TF1'\n",
    "# Define micasa variables wanted\n",
    "micasa_var_list = ['NEE', 'NPP']\n",
    "# Extract site lat/lon\n",
    "site_lat = ameriflux_meta.loc[ameriflux_meta['Site ID'] == site_ID, 'Latitude (degrees)'].values\n",
    "site_lon = ameriflux_meta.loc[ameriflux_meta['Site ID'] == site_ID, 'Longitude (degrees)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87344856-e94f-4c11-b310-22a468d56c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import fluxnet \n",
    "fluxnet_sel = pd.read_csv(get_amer_match(amer_filepath, site_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182e811-5c0d-465e-b535-9cace5249b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxnet_sel_dates = fluxnet_sel.loc[:,['TIMESTAMP']].copy()\n",
    "fluxnet_sel_dates['TIMESTAMP'] = pd.to_datetime(fluxnet_sel_dates['TIMESTAMP'],format='%Y%m%d')\n",
    "fluxnet_sel_dates = fluxnet_sel_dates.set_index('TIMESTAMP')\n",
    "time = fluxnet_sel_dates.index\n",
    "dates_unique = list({dt.date() for dt in time})\n",
    "dates_unique.sort()\n",
    "dates_unique[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8330aa3-2fb2-4337-8f9a-95ef11aa2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import micasa\n",
    "# Test some random files\n",
    "path_test_mon = glob.glob(mic_filepath + 'daily-0.1deg-final/holding/daily/2016/01/MiCASA_v1_flux_x3600_y1800_daily_201601*')\n",
    "path_sorted_mon = sorted(path_test_mon)\n",
    "\n",
    "path_test_yr = glob.glob(mic_filepath + 'daily-0.1deg-final/holding/daily/2016/??/MiCASA_v1_flux_x3600_y1800_daily_20??????.nc4')\n",
    "path_sorted_yr = sorted(path_test_yr)\n",
    "\n",
    "path_test_all = glob.glob(mic_filepath + 'daily-0.1deg-final/holding/daily/20??/??/MiCASA_v1_flux_x3600_y1800_daily_20??????.nc4')\n",
    "path_sorted_all = sorted(path_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037efa81-700d-4d87-87b1-2a4e0f07c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(path_sorted_mon[0], len(path_sorted_mon), len(path_sorted_yr), len(path_sorted_all), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecdfb5-a9e3-41c5-a897-d2338d88c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ds = xr.open_mfdataset(path_test_mon)\n",
    "# ds = xr.open_mfdataset(path_sorted_mon)[micasa_var_list] \n",
    "ds = xr.open_mfdataset(path_sorted_mon, combine='nested', concat_dim='time')[micasa_var_list]\n",
    "# ds = xr.open_mfdataset(path_sorted_mon, parallel=True)[micasa_var_list] #Test this when I can get the dashboard to work\n",
    "ds\n",
    "\n",
    "# Note: \n",
    "# Not clear how fast combine=nested, concat_dim='time' improves speed over default combine='by-coords'\n",
    "# Adding in just relevant variables seems to shorten time several seconds for 1 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61127deb-6bb0-4601-a2e7-a77ea6dc6b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMO this is all slow and i should virtualize... because then I can reuse the virtualized store for across all sites, since there are year crossovers?\n",
    "# Or perhaps I should load all the micasa data at once and subset from there? That would avoid opening some files multiple times\n",
    "# How long does it take to open the micasa data? ~10 seconds for 1 month, 1:30 for 1 year, too long to run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be80a7cc-f3b9-437c-a0d4-8652bc47fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "ds_subset = ds.sel(lon=site_lon, lat=site_lat, method='nearest')\n",
    "ds_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a120de-d5f4-4706-b2d3-a2cd4cf31fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_out = pd.DataFrame()\n",
    "# with xr.open_mfdataset(path_test_mon)[micasa_var_list] as ds:\n",
    "#     # Select grid closest to selected site\n",
    "#     ds_subset = ds.sel(lon=site_lon, lat=site_lat, method='nearest')\n",
    "#     # print(ds_subset)\n",
    "    \n",
    "#     # Prep data for writing to csv\n",
    "#     ds_subset = ds_subset.squeeze(dim=['lat','lon'],drop=True)\n",
    "#     # print(ds_subset)\n",
    "    \n",
    "#     # Output a single file for each site with all variables\n",
    "#     for micasa_var in micasa_var_list:\n",
    "#         ds_out[micasa_var] = ds_subset[micasa_var].to_dataframe()\n",
    "#         ds_out.rename(columns={micasa_var: f'MiCASA {micasa_var} ({ds_subset[micasa_var].units})'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bd7f44-0415-4282-99d5-f92f9ede5c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis",
   "language": "python",
   "name": "data-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
